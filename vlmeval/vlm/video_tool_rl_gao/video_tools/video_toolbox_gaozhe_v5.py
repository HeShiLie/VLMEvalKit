import numpy as np
import copy
from .tool_envs import ToolBase
from typing import Optional, List, Dict, Any
from PIL import Image
import re
import json
import requests

import traceback
import omegaconf

from PIL import Image
import cv2

def get_video_duration_cv2(video_path):
    """
    ä½¿ç”¨ OpenCV è·å–è§†é¢‘æ—¶é•¿, è¿”å›è§†é¢‘æ—¶é•¿(ç§’),å‘ä¸‹å–æ•´
    
    Args:
        video_path (str): è§†é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        int: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å› -1
    """
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return -1
        
        # è·å–å¸§ç‡å’Œæ€»å¸§æ•°
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        
        cap.release()
        
        if fps > 0:
            duration = int(frame_count / fps)
            return duration
        else:
            return -1
            
    except Exception as e:
        print(f"Error getting video duration: {e}")
        return -1

def check_previous_tool_call(tool_name, tools_call_state_list): # tools_call_state_listæ˜¯ä¸ª
    # idx å®é™…ä¸Šæ˜¯åœ¨è¿™ä¸ªbsz*n é‡Œçš„index
    if tool_name == 'video_perceiver_tool':
        # ä»åå¾€å‰æ£€æŸ¥, å‰é¢æœ‰æ²¡æœ‰è°ƒç”¨è¿‡ video_image_retriever_tool
        for i in range(len(tools_call_state_list)-1, -1, -1):
            if tools_call_state_list[i]['info_stated']['tool_name'] == 'video_image_retriever_tool':
                return True

    elif tool_name == 'video_frame_grounder_tool':
        # ä»åå¾€å‰æ£€æŸ¥, å‰é¢æœ‰æ²¡æœ‰è°ƒç”¨è¿‡ video_perceiver_tool
        for i in range(len(tools_call_state_list)-1, -1, -1):
            if tools_call_state_list[i]['info_stated']['tool_name'] == 'video_perceiver_tool':
                return True        

    else:
        return False

def get_ouput_from_previous_tool_call(tool_name, tools_call_state_list):
    # idx å®é™…ä¸Šæ˜¯åœ¨è¿™ä¸ªbsz*n é‡Œçš„index
    if tool_name == 'video_perceiver_tool':
        # å¯¹äºè¿™ä¸ª tools_call_state_list (å…±bsz*nä¸ªtraj), å…ˆæŠŠidxå¯¹åº”çš„é‚£ä¸€ä¸²æ‹¿å‡ºæ¥
        # ä»åå¾€å‰æ£€æŸ¥, å‰é¢æœ‰æ²¡æœ‰è°ƒç”¨è¿‡ video_image_retriever_tool
        for i in range(len(tools_call_state_list)-1, -1, -1):
            if tools_call_state_list[i]['info_stated']['tool_name'] == 'video_image_retriever_tool':
                return tools_call_state_list[i]['info_stated']['video_clip_paths']
    elif tool_name == 'video_frame_grounder_tool':
        # å¯¹äºè¿™ä¸ª tools_call_state_list (å…±bsz*nä¸ªtraj), å…ˆæŠŠidxå¯¹åº”çš„é‚£ä¸€ä¸²æ‹¿å‡ºæ¥
        # ä»åå¾€å‰æ£€æŸ¥, å‰é¢æœ‰æ²¡æœ‰è°ƒç”¨è¿‡ 
        for i in range(len(tools_call_state_list)-1, -1, -1):
            if tools_call_state_list[i]['info_stated']['tool_name'] == 'video_perceiver_tool':
                return tools_call_state_list[i]['info_stated']['selected_image_path']
    else:
        raise ValueError(f"Unsupported tool name: {tool_name}. Cannot retrieve output from previous tool call.")

def filter_short_clips(video_paths: list[str], min_frames: int = 30) -> list[str]:
    """
    è¿‡æ»¤æ‰å¸§æ•°å°äºç­‰äº min_frames çš„è§†é¢‘è·¯å¾„

    Args:
        video_paths (list[str]): è§†é¢‘è·¯å¾„åˆ—è¡¨
        min_frames (int): æœ€å°å¸§æ•°è¦æ±‚ï¼ˆé»˜è®¤30ï¼‰

    Returns:
        list[str]: è¿‡æ»¤åçš„è·¯å¾„åˆ—è¡¨
    """
    valid_paths = []
    for path in video_paths:
        cap = cv2.VideoCapture(path)
        if not cap.isOpened():
            print(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{path}")
            continue
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()

        if frame_count > min_frames:
            valid_paths.append(path)
        else:
            print(f"ä¸¢å¼ƒå¸§æ•° {frame_count} çš„è§†é¢‘ï¼š{path}")

    return valid_paths


def outloading_retriver(video_path: str, clip_save_folder: str, question: str, topk: int, duration: int, 
                       service_url: str = "http://localhost:17860", max_retries: int = 5, 
                       retry_delay: float = 10.0, request_timeout: int = 300):
    """
    é€šè¿‡è¿œç¨‹æœåŠ¡è°ƒç”¨ Retrieval Manager è¿›è¡Œè§†é¢‘æ£€ç´¢
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
        clip_save_folder: ç‰‡æ®µä¿å­˜ç›®å½•
        question: æŸ¥è¯¢é—®é¢˜
        topk: è¿”å›å‰kä¸ªç»“æœ
        duration: è§†é¢‘æ—¶é•¿
        service_url: æ£€ç´¢æœåŠ¡çš„URL
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤5æ¬¡ï¼‰
        retry_delay: é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤10ç§’ï¼‰
        request_timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤600ç§’ï¼‰
        
    Returns:
        video_clip_paths: è§†é¢‘ç‰‡æ®µè·¯å¾„åˆ—è¡¨
    """
    import requests
    import json
    import time
    
    # é‡è¯•æœºåˆ¶ä¸»å¾ªç¯
    for attempt in range(max_retries + 1):
        try:
            # æ–¹æ³•1: é¦–å…ˆå°è¯•ä½¿ç”¨ gradio_clientï¼ˆæ¨èæ–¹å¼ï¼‰
            try:
                from gradio_client import Client
                
                print(f"[INFO] ä½¿ç”¨ gradio_client è¿æ¥åˆ°æ£€ç´¢æœåŠ¡: {service_url} (å°è¯• {attempt + 1}/{max_retries + 1})")
                client = Client(service_url)
                
                # è°ƒç”¨è§†é¢‘æ£€ç´¢API
                result = client.predict(
                    video_path,
                    question,
                    topk,
                    duration,
                    clip_save_folder,
                    api_name="/predict_1"
                )
                
                if isinstance(result, dict) and result.get("success", False):
                    video_clip_paths = result["video_clip_paths"]
                    # è¿‡æ»¤çŸ­ç‰‡æ®µ
                    video_clip_paths = filter_short_clips(video_clip_paths, min_frames=60)
                    print(f"[INFO] æ£€ç´¢æœåŠ¡è¿”å› {len(video_clip_paths)} ä¸ªæœ‰æ•ˆç‰‡æ®µ (å°è¯• {attempt + 1} æˆåŠŸ)")
                    return video_clip_paths
                else:
                    error_msg = result.get("error", "gradio_clientè°ƒç”¨å¤±è´¥") if isinstance(result, dict) else "æ„å¤–çš„è¿”å›æ ¼å¼"
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡å¿™ç¢Œé”™è¯¯
                    if "busy" in str(error_msg).lower() or "queue" in str(error_msg).lower() or "occupied" in str(error_msg).lower():
                        if attempt < max_retries:
                            print(f"[WARNING] æœåŠ¡å¿™ç¢Œï¼Œ{retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries + 1})")
                            time.sleep(retry_delay)
                            continue
                    
                    raise Exception(f"gradio_clientè°ƒç”¨å¤±è´¥: {error_msg}")
                    
            except ImportError:
                print("[WARNING] gradio_client æœªå®‰è£…ï¼Œå°è¯•HTTPè¯·æ±‚æ–¹å¼")
                raise Exception("gradio_client æœªå®‰è£…")
            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡å¿™ç¢Œç›¸å…³çš„é”™è¯¯
                error_str = str(e).lower()
                if any(keyword in error_str for keyword in ["busy", "queue", "occupied", "timeout", "connection"]):
                    if attempt < max_retries:
                        print(f"[WARNING] [video_toolbox_gaozhe_v5.outloading_retriver] gradio_client è°ƒç”¨å¤±è´¥ (æœåŠ¡å¿™ç¢Œç›¸å…³): {str(e)}")
                        print(f"[INFO] [video_toolbox_gaozhe_v5.outloading_retriver] {retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries + 1})")
                        time.sleep(retry_delay)
                        continue
                
                print(f"[WARNING] [video_toolbox_gaozhe_v5.outloading_retriver] gradio_client è°ƒç”¨å¤±è´¥ (éæœåŠ¡å¿™ç¢ŒåŸå› ): {str(e)}")
                print(f"[INFO] [video_toolbox_gaozhe_v5.outloading_retriver] å°è¯•HTTPè¯·æ±‚æ–¹å¼...")
                raise Exception(f"gradio_client å¤±è´¥: {str(e)}")
        
        except Exception as gradio_error:
            # æ–¹æ³•2: å›é€€åˆ°HTTPè¯·æ±‚æ–¹å¼
            try:
                print(f"[INFO] å°è¯•HTTPè¯·æ±‚æ–¹å¼... (å°è¯• {attempt + 1}/{max_retries + 1})")
                
                # å°è¯•æ–°çš„Gradio APIç«¯ç‚¹
                success = False
                for api_endpoint in ["/gradio_api/predict_1", "/predict_1"]:
                    try:
                        api_url = f"{service_url}{api_endpoint}"
                        
                        response = requests.post(
                            api_url,
                            json={
                                "data": [video_path, question, topk, duration, clip_save_folder],
                                "session_hash": "retrieval_session"
                            },
                            headers={"Content-Type": "application/json"},
                            timeout=request_timeout
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            
                            # å¤„ç†Gradioè¿”å›æ ¼å¼
                            if "data" in result and len(result["data"]) > 0:
                                result_data = result["data"][0]
                                
                                # å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æJSON
                                if isinstance(result_data, str):
                                    try:
                                        result_json = json.loads(result_data)
                                    except json.JSONDecodeError:
                                        result_json = {"success": False, "error": f"æ— æ³•è§£æè¿”å›æ•°æ®: {result_data}"}
                                elif isinstance(result_data, dict):
                                    result_json = result_data
                                else:
                                    result_json = {"success": False, "error": f"æ„å¤–çš„è¿”å›æ•°æ®ç±»å‹: {type(result_data)}"}
                                    
                                if result_json.get("success", False):
                                    video_clip_paths = result_json["video_clip_paths"]
                                    video_clip_paths = filter_short_clips(video_clip_paths, min_frames=60)
                                    print(f"[INFO] HTTPè¯·æ±‚æˆåŠŸï¼Œè¿”å› {len(video_clip_paths)} ä¸ªæœ‰æ•ˆç‰‡æ®µ (å°è¯• {attempt + 1} æˆåŠŸ)")
                                    return video_clip_paths
                                else:
                                    error_msg = result_json.get("error", "HTTPè¯·æ±‚è¿”å›é”™è¯¯")
                                    
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡å¿™ç¢Œé”™è¯¯
                                    if any(keyword in str(error_msg).lower() for keyword in ["busy", "queue", "occupied"]):
                                        print(f"[WARNING] æœåŠ¡å¿™ç¢Œ ({api_endpoint}): {error_msg}")
                                        break  # é€€å‡ºAPIç«¯ç‚¹å¾ªç¯ï¼Œè¿›è¡Œé‡è¯•
                                    else:
                                        print(f"[WARNING] HTTPè¯·æ±‚å¤±è´¥ ({api_endpoint}): {error_msg}")
                                        continue
                            else:
                                print(f"[WARNING] HTTPè¯·æ±‚è¿”å›æ— æ•ˆæ ¼å¼ ({api_endpoint})")
                                continue
                        elif response.status_code == 503:  # æœåŠ¡ä¸å¯ç”¨
                            print(f"[WARNING] æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ ({api_endpoint}): {response.status_code}")
                            break  # é€€å‡ºAPIç«¯ç‚¹å¾ªç¯ï¼Œè¿›è¡Œé‡è¯•
                        else:
                            print(f"[WARNING] HTTPè¯·æ±‚å¤±è´¥ ({api_endpoint}): {response.status_code} - {response.text}")
                            continue
                            
                    except requests.exceptions.Timeout:
                        print(f"[WARNING] HTTPè¯·æ±‚è¶…æ—¶ ({api_endpoint})")
                        break  # é€€å‡ºAPIç«¯ç‚¹å¾ªç¯ï¼Œè¿›è¡Œé‡è¯•
                    except requests.exceptions.ConnectionError:
                        print(f"[WARNING] æ— æ³•è¿æ¥åˆ°æœåŠ¡ ({api_endpoint})")
                        break  # é€€å‡ºAPIç«¯ç‚¹å¾ªç¯ï¼Œè¿›è¡Œé‡è¯•
                    except requests.exceptions.RequestException as req_error:
                        print(f"[WARNING] HTTPè¯·æ±‚å¼‚å¸¸ ({api_endpoint}): {str(req_error)}")
                        continue
                
                # å¦‚æœåˆ°è¿™é‡Œè¯´æ˜æ‰€æœ‰HTTPç«¯ç‚¹éƒ½å¤±è´¥äº†ï¼Œä½†å¯èƒ½æ˜¯ä¸´æ—¶æ€§çš„
                if attempt < max_retries:
                    print(f"[WARNING] æ‰€æœ‰HTTPç«¯ç‚¹éƒ½æ— æ³•è®¿é—®ï¼Œ{retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries + 1})")
                    time.sleep(retry_delay)
                    continue
                else:
                    raise Exception("æ‰€æœ‰HTTPç«¯ç‚¹éƒ½æ— æ³•è®¿é—®")
                
            except Exception as http_error:
                error_str = str(http_error).lower()
                if any(keyword in error_str for keyword in ["busy", "queue", "occupied", "timeout", "connection"]) and attempt < max_retries:
                    print(f"[WARNING] HTTPè¯·æ±‚å¤±è´¥ (å¯èƒ½æœåŠ¡å¿™ç¢Œ): {str(http_error)}")
                    print(f"[INFO] {retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries + 1})")
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"[ERROR] HTTPè¯·æ±‚æ–¹å¼ä¹Ÿå¤±è´¥äº†: {str(http_error)}")
                    if attempt >= max_retries:
                        raise Exception(f"æ£€ç´¢æœåŠ¡ä¸å¯ç”¨: gradio_clientå’ŒHTTPè¯·æ±‚éƒ½å¤±è´¥ - {str(http_error)}")
                    else:
                        time.sleep(retry_delay)
                        continue
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    raise Exception(f"æ£€ç´¢æœåŠ¡åœ¨ {max_retries + 1} æ¬¡å°è¯•åä»ç„¶ä¸å¯ç”¨ï¼Œå¯èƒ½model poolå…¨è¢«å ç”¨")

class VideoToolBoxV5(ToolBase):
    name = "video_toolbox_v5" #CHANGE BACK AFTER DEBUG
    user_prompt = "Here is the observation returned after you executed the tool call." #todo: maybe we should change the prompt to let the model know how to use the tools

    def __init__(self, _name, _desc, _params, **kwargs):
        super().__init__(
            name=self.name,
        )
        self.chatml_history = []
        self.multi_modal_data = None  # To store the current video being processed
        
        # æ£€ç´¢æœåŠ¡ç°åœ¨ç”± ParallelEnv ç®¡ç†ï¼Œè¿™é‡Œä¸å†éœ€è¦å¯åŠ¨
        print(f"ğŸ“ [VideoToolBoxV5] æ£€ç´¢æœåŠ¡ç”± ParallelEnv ç®¡ç†")

    def extract_answer(self, action_string: str) -> Dict[str, any]:
        answer = re.search(r'<answer>(.*?)</answer>', action_string, re.DOTALL)
        return answer
    
    def extract_action(self, action_string: str) -> Dict[str, Any]:
        """
        Extracts the tool call from the action string.
        
        Args:
            action_string: The string containing the tool call in XML tags.
            
        Returns:
            A dictionary with the tool name and arguments.
            
        Raises:
            ValueError: If no tool call is found or JSON is invalid.
        """
        tool_call_match = re.search(r'<tool_call>(.*?)</tool_call>', action_string, re.DOTALL)
        if not tool_call_match:
            raise ValueError("No tool call found in the action string.")
        
        tool_call_json = tool_call_match.group(1).strip()
        try:
            tool_call = json.loads(tool_call_json)
            return tool_call
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in tool call: {e}")
        
    def execute(self, action_string: str, **kwargs) -> tuple:
        """
        Execute the tool functionality based on the action string.
        
        Args:
            action_string: The string containing the tool call in XML tags.
            
        Returns:
            observation: The structured observation with the processed image.
            reward: 0.1 if tool call is successful with correct JSON format, 0 otherwise.
            done: Whether the episode is terminated.
            info: Additional info.
        """
        # print(f"[DEBUG] kwargs['video_path_list'][idx] {kwargs['video_path_list'][idx]}")
        current_image = None # * DEBUG
        current_video_paths = [] # * DEBUG

        try:
            answer = self.extract_answer(action_string)
            if answer:
                return "", 0.0, True, {}
            tool_call = self.extract_action(action_string)
            tool_name = tool_call["name"]
            args = tool_call["arguments"]
            
            #! here adding the customized tools
            if tool_name == "video_image_retriever_tool":

                video_path = kwargs['video_path']  # Get the video path from kwargs
                question = args['retrieving_sentence']
                clip_save_folder = "./temp_v5/clip_save_folder"
                topk=args['topk']
                duration = get_video_duration_cv2(video_path)  # Get the video duration
                
                # æ£€æŸ¥æ˜¯å¦æä¾›äº†æœåŠ¡URLå‚æ•°
                service_url = kwargs.get('retrieval_service_url', 'http://localhost:17860')
                
                # æ£€ç´¢é…ç½®å‚æ•°ï¼ˆå¯é€‰ï¼‰
                max_retries = kwargs.get('retrieval_max_retries', 5)
                retry_delay = kwargs.get('retrieval_retry_delay', 10.0)
                request_timeout = kwargs.get('retrieval_timeout', 600)

                video_clip_paths = outloading_retriver(
                    video_path, clip_save_folder, question, topk, duration, 
                    service_url, max_retries, retry_delay, request_timeout
                ) # Get the video clip paths

                current_image = [] # *  # No image to return for this tool
                current_video_paths = video_clip_paths  # List of video clip paths
                # current_video_paths = [] # * TOCHECK
                
                info_need_to_stated = {
                    "tool_name": tool_name,
                    "video_clip_paths": video_clip_paths,
                    "video_path": video_path,
                    "duration": duration,
                }
  
            elif tool_name == "video_perceiver_tool": #! maybe problemetic
                # ä»ä¸€ä¸ªlisté‡Œçš„video clip pathsä¸­é€‰æ‹© æŸä¸ª clip,å¹¶æŒ‡å‡ºå“ªä¸€å¸§æœ€æ¥è¿‘
                clip_idx = args.get("clip_idx", 0)  # Default to the first clip if not specified
                if check_previous_tool_call(tool_name, kwargs['tools_call_state_list']): #kwargs['tools_call_state_list'] æ˜¯ä¸ªlist, è¦ä¹ˆæ˜¯â€˜no_tool_callâ€™ è¦ä¹ˆè§infoçš„æ ¼å¼
                    video_clip_paths = get_ouput_from_previous_tool_call(tool_name, kwargs['tools_call_state_list'])
                else:
                    raise ValueError("[DEBUG] tool ||{tool_name}|| No video clip paths available. Please run the video_image_retriever_tool first.")
                
                if args["clip_idx"] >= len(video_clip_paths):
                    raise ValueError(f"[DEBUG] tool ||{tool_name}|| clip_idx {args['clip_idx']} out of range for video_clip_paths with length {len(video_clip_paths)}.")
                selected_clip_path = video_clip_paths[clip_idx]
                # read the video clip
                import cv2
                cap = cv2.VideoCapture(selected_clip_path)
                if not cap.isOpened():
                    raise ValueError(f"[DEBUG] tool ||{tool_name}|| Cannot open video clip: {selected_clip_path}")
                frame_idx = args.get("frame_idx", 0)  # Default to the first frame if not specified
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                success, frame = cap.read()  # Read the specified frame
                if not success:
                    raise ValueError(f"[DEBUG] tool ||{tool_name}|| Failed to read frame {frame_idx} from video clip {selected_clip_path}.")
                # Convert the frame to a numpy array
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB
                frame = Image.fromarray(frame)  # Convert to PIL Image

                current_image = [frame]  # Wrap in a list to match expected format
                video_clip_paths = []  # Return the selected clip path

                # save to clip_path_frame_"frame"_x_"coord_x"_y_"coord_y".png
                selected_image_path = f"{selected_clip_path}_frame_{frame_idx}.png"
                frame.save(selected_image_path)
                print(f"[DEBUG] tool ||{tool_name}|| saved to {selected_image_path}")

                info_need_to_stated = {
                    "tool_name": tool_name,
                    "clip_resolution": frame.size,
                    "selected_image_path": selected_image_path
                    }

            elif tool_name == "video_frame_grounder_tool": 
                # check whether the perceiver is called before
                if check_previous_tool_call(tool_name, kwargs['tools_call_state_list']): 
                    selected_image_path = get_ouput_from_previous_tool_call(tool_name, kwargs['tools_call_state_list'])
                else:
                    raise ValueError("[DEBUG] tool ||{tool_name}|| No selected image path available. Please run the video_image_perceiver_tool first.")

                bbox = args["bbox_2d"] # (x1,y1,x2,y2)
                img = Image.open(selected_image_path)
                # img_size = 

                cropped_img = img.crop(bbox)

                if cropped_img.size == (0,0):
                    raise ValueError("[DEBUG] tool ||{tool_name}|| [ERROR] crop into (0,0) image.")

                
                current_image = [cropped_img]

                info_need_to_stated = {
                    "tool_name": tool_name,
                    "bbox_2d": bbox,
                }


            elif tool_name == "video_browser_tool": #! å®é™…ä¸Šè¿™ä¸ªå·¥å…·è°ƒç”¨ä¼˜å…ˆçº§åº”å½“æœ€é«˜
                # 1. random select several frames from the entire video
                video_path = kwargs['video_path']
                num_frames = 15
                
                import cv2
                import random
                import numpy as np

                cap = cv2.VideoCapture(video_path)
                if not cap.isOpened():
                    raise ValueError(f"[DEBUG] tool ||{tool_name}|| Cannot open video: {video_path}")
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                # å¦‚æœè§†é¢‘å¸§æ•°å°‘äºéœ€è¦çš„å¸§æ•°ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if total_frames < num_frames:
                    raise ValueError(f"[DEBUG] tool ||{tool_name}|| Video has fewer frames ({total_frames}) than requested ({num_frames}).") #todo: maybe not raise ValueError
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªèµ·å§‹ç‚¹ï¼Œç¡®ä¿åç»­ num_frames å¸§ä¸ä¼šè¶…å‡ºæ€»å¸§æ•°
                start_frame = random.randint(0, total_frames - num_frames)

                # åˆ›å»º (T, C, H, W) çš„å¼ é‡
                video_tensor = np.zeros((num_frames, 3, 224, 224), dtype=np.uint8)

                for t in range(num_frames):
                    # è®¾ç½®è§†é¢‘è¯»å–çš„ä½ç½®
                    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame + t)
                    success, frame = cap.read()  # è¯»å–å¸§
                    if not success:
                        raise ValueError(f"[DEBUG] tool ||{tool_name}|| Failed to read frame {start_frame + t} from video.")

                    # è°ƒæ•´å¸§å¤§å°ä¸ºæŒ‡å®šçš„ frame_size (H, W)ï¼Œå¹¶å°†é€šé“é¡ºåºä» HWC è½¬ä¸º CHW
                    resized_frame = cv2.resize(frame, (224, 224))
                    # print(f"[DEBUG] tool ||{tool_name}|| Resized frame shape: {resized_frame.shape}")
                    video_tensor[t] = np.transpose(resized_frame, (2, 0, 1))  # HWC -> CHW

                cap.release()  # é‡Šæ”¾èµ„æº

                current_image = [Image.fromarray(video_tensor[i], mode = 'RGB') for i in range(video_tensor.shape[0])]  # Convert to list of images
                video_clip_paths = []

                info_need_to_stated = {
                    "tool_name": tool_name,
                    "video_path": video_path,
                    "num_frames": num_frames,
                }
    
            else:
                raise ValueError(f"Unknown tool name: {tool_name}")
            
            # Prepare the observation
            #! åˆ°æ—¶å€™tokenizer.encode, ä»–è‡ªå·±å†™çš„æ ¼å¼è½¬æ¢çš„ä»£ç ,ä¸­é—´çš„è¯´ä¸å®šè¿˜ä¸ç”¨æ”¹
            # * CHECK
            image_str = "<image>" if current_image else ""
            # video_str = "<video>"*len(current_video_paths) if current_video_paths else ""
            video_str = ", ".join(
                [f"video clip {i+1}: <video>" for i in range(len(current_video_paths))]
            ) if current_video_paths else ""
            # TODO DONE: support multi images/videos 
            obs = {
                "prompt": "<|im_end|>\n<|im_start|>user\n" + video_str + image_str + self.user_prompt + "<|im_end|>\n<|im_start|>assistant\n",
                # "prompt": "<|im_end|>\n<|im_start|>user\n" + video_str + image_str + self.user_prompt + "\nThink first, then call tools. Format strictly as: <think>...</think> <tool_call>...</tool_call>" + "<|im_end|>\n<|im_start|>assistant\n",

                "multi_modal_data": {"image": [current_image[0]] if current_image else [], "video": None}, #  current_image: List[Image]
                # "vision_infos": {"image": None, "video": [current_video_paths[0]] if current_video_paths else []},
                "vision_infos": {"image": None, "video": current_video_paths if current_video_paths else []},
                "tool_name": tool_name, 
            }
            reward = 0.5  # Reward for successful tool call with correct JSON
            done = False
            info = {"status": "success", "tool_used": tool_name, "info_stated": info_need_to_stated}
            # print(f'[DEBUG] SUCCESS ACTION AT STEP {len(kwargs["tools_call_state_list"])} The str is {action_string=}')
            return obs, reward, done, info
            
        except Exception as e:
            error_traceback = traceback.format_exc()
            # Return an error observation if something goes wrong
            print(f'[DEBUG] Execute WRONG - {str(e)}')
            # print(f'[DEBUG] FAILED ACTION AT STEP {len(kwargs["tools_call_state_list"])} {action_string=}')
            print(f'[DEBUG] Traceback:\n{error_traceback}')
            obs = {
                "prompt": f"<|im_start|>user\nError: {str(e)}<|im_end|>\n<|im_start|>assistant\n",
                "multi_model_data": None,
            }
            reward = 0.0  # No reward for failed execution
            done = False
            info = {"error": str(e), "status": "failed"}
            return obs, reward, done, info
        
    def reset(self, raw_prompt, multi_modal_data, origin_multi_modal_data, **kwargs):
        self.chatml_history = raw_prompt
        self.multi_modal_data = origin_multi_modal_data

if __name__ == "__main__":
    # Example usage (for testing)
    tool = VideoToolBoxV5("video_toolbox", "Tool for video processing", {})
    tool.multi_modal_data={
        "video_path": "/mnt/gz/Data/ActivityNetQA/ActivityNetQA/all_test/v__-JNaelSKO8.mp4",  # Example video path and duration in seconds
        "duration": 28,  # Example video path and duration in seconds
        "image": None,
        "question": "What is the main activity in this video?",
    }
    
    video_image_retriever_action = """
    <tool_call>
    {"name": "video_image_retriever_tool", "arguments": {"topk": 1}}
    </tool_call>
    """
    obs, reward, done, info = tool.execute(video_image_retriever_action)
    print(f"Zoom in result - Reward: {reward}, Info: {info}")
    print(obs)
    
    # video_perceiver_action = """
    # <tool_call>
    # {"name": "video_perceiver_tool", "arguments": {"clip_idx": 0, "frame_idx": 0}}
    # </tool_call>
    # """
    # obs, reward, done, info = tool.execute(video_perceiver_action)
    # print(f"Rotate result - Reward: {reward}, Info: {info}")
    
    # video_frame_grounder_action = """
    # <tool_call>
    # {"name": "video_frame_grounder_tool", "arguments": {"bbox": [0,0, 100, 100]}}
    # </tool_call>
    # """
    # obs, reward, done, info = tool.execute(video_frame_grounder_action)
    # print(f"Rotate result - Reward: {reward}, Info: {info}")

    # video_browser_action = """
    # <tool_call>
    # {"name": "video_browser_tool", "arguments": None}
    # </tool_call>
    # """
    # obs, reward, done, info = tool.execute(video_browser_action)
    # print(f"Rotate result - Reward: {reward}, Info: {info}")

    # # Test invalid JSON (should return reward=0.0)
    # invalid_action = """
    # <tool_call>
    # {"name": "video_image_retriever_tool", "arguments": {"image_path": "test.jpg", "angle": 90}
    # </tool_call>
    # """
    # obs, reward, done, info = tool.execute(invalid_action)
    # print(f"Invalid JSON result - Reward: {reward}, Info: {info}")
    
    # # Test unknown tool (should return reward=0.0)
    # unknown_tool_action = """
    # <tool_call>
    # {"name": "unknown_tool", "arguments": {"param": "value"}}
    # </tool_call>
    # """
    # obs, reward, done, info = tool.execute(unknown_tool_action)
    # print(f"Unknown tool result - Reward: {reward}, Info: {info}")