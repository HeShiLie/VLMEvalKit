from transformers import Qwen2_5_VLForConditionalGeneration
from transformers import AutoTokenizer
import torch

hf_model = Qwen2_5_VLForConditionalGeneration.from_pretrained('/workspace/codes/DeepEyes/verl_checkpoints/agent_vlagent_0717/debug_for_single_node_qw2_5vl-7b-instruct/global_step_8/actor/hf_merged/')
tokenizer = AutoTokenizer.from_pretrained('/workspace/codes/DeepEyes/verl_checkpoints/agent_vlagent_0717/debug_for_single_node_qw2_5vl-7b-instruct/global_step_8/actor/hf_merged/')

hf_model.to('cuda:0')
imput_prompt_id = torch.tensor([[151644, 8948, 198, 31999, 3641, 3736, 279, 2766, 323, 2291, 6529, 311, 279, 5240, 323, 8500, 315, 4357, 11, 279, 7716, 323, 7203, 315, 6171, 11, 323, 279, 1917, 323, 17040, 315, 11186, 13, 20205, 389, 697, 23722, 11, 3293, 279, 1850, 2999, 429, 29257, 14230, 279, 3405, 624, 2610, 525, 264, 10950, 17847, 382, 2, 13852, 198, 2610, 1231, 1618, 825, 476, 803, 5746, 311, 7789, 448, 279, 1196, 3239, 624, 2610, 525, 3897, 448, 729, 32628, 2878, 366, 15918, 1472, 15918, 29, 11874, 9492, 510, 27, 15918, 397, 4913, 1313, 3252, 1688, 2198, 1688, 22317, 606, 3252, 9986, 4954, 1288, 8927, 423, 22785, 2198, 4684, 3252, 2679, 279, 2766, 374, 2238, 1293, 11, 990, 419, 5392, 311, 3931, 279, 6803, 1119, 2613, 26111, 323, 3293, 1909, 74, 26111, 429, 1429, 48293, 311, 279, 1196, 594, 2661, 3405, 47891, 13786, 22317, 1313, 3252, 1700, 2198, 13193, 22317, 3481, 74, 22317, 1313, 3252, 396, 2198, 3615, 22317, 1313, 3252, 4082, 58640, 1065, 4353, 788, 16, 1335, 2810, 4353, 788, 20, 1335, 4684, 3252, 785, 1372, 315, 1429, 48293, 26111, 311, 387, 4091, 13, 1416, 1052, 525, 5248, 31327, 26111, 11, 279, 897, 1265, 387, 438, 3460, 438, 3204, 11, 537, 47905, 330, 2810, 4353, 497, 323, 518, 3245, 330, 2810, 4353, 1, 31327, 26111, 1265, 387, 4091, 1189, 3417, 1335, 6279, 36799, 3481, 74, 1341, 3417, 532, 522, 15918, 1339, 2, 2585, 311, 1618, 264, 5392, 198, 5598, 264, 2951, 1633, 448, 729, 829, 323, 5977, 2878, 220, 151657, 151658, 11874, 9492, 510, 151657, 198, 4913, 606, 788, 366, 1688, 11494, 8066, 330, 16370, 788, 366, 2116, 56080, 40432, 31296, 151658, 271, 334, 13314, 95518, 715, 151657, 715, 4913, 606, 788, 330, 9986, 4954, 1288, 8927, 423, 22785, 497, 330, 16370, 788, 5212, 3481, 74, 788, 220, 17, 3417, 715, 151658, 198, 27, 15918, 397, 4913, 1313, 3252, 1688, 2198, 1688, 22317, 606, 3252, 9986, 5678, 12862, 22785, 2198, 4684, 3252, 2679, 1052, 594, 3807, 26111, 714, 2058, 2588, 311, 4226, 279, 3405, 11, 990, 419, 5392, 311, 1156, 3293, 279, 1429, 3405, 45613, 9721, 12327, 323, 279, 1429, 48293, 4034, 13, 2014, 653, 773, 11, 498, 1184, 311, 1459, 700, 892, 12327, 374, 279, 1429, 48293, 825, 323, 892, 4034, 374, 279, 1429, 48293, 825, 448, 7187, 304, 279, 1352, 315, 5109, 47891, 13786, 22317, 1313, 3252, 1700, 2198, 13193, 22317, 7974, 7258, 22317, 1313, 3252, 396, 2198, 3615, 22317, 1313, 3252, 4082, 58640, 1065, 4353, 788, 16, 1335, 2810, 4353, 788, 16, 1335, 4684, 3252, 785, 7187, 315, 279, 1429, 48293, 12327, 7707, 448, 279, 3405, 11, 537, 47905, 330, 2810, 4353, 497, 323, 518, 3245, 330, 2810, 4353, 1, 31327, 26111, 1265, 387, 4091, 1189, 51193, 6763, 7258, 22317, 1313, 3252, 396, 2198, 4684, 3252, 785, 7187, 315, 279, 1429, 48293, 4034, 304, 279, 4091, 12327, 1189, 3417, 1335, 6279, 36799, 7974, 7258, 2198, 6763, 7258, 1341, 3417, 532, 522, 15918, 1339, 2, 2585, 311, 1618, 264, 5392, 198, 5598, 264, 2951, 1633, 448, 729, 829, 323, 5977, 2878, 220, 151657, 151658, 11874, 9492, 510, 151657, 198, 4913, 606, 788, 366, 1688, 11494, 8066, 330, 16370, 788, 366, 2116, 56080, 40432, 31296, 151658, 271, 334, 13314, 95518, 715, 151657, 715, 4913, 606, 788, 330, 9986, 5678, 12862, 22785, 497, 330, 16370, 788, 5212, 7974, 7258, 788, 220, 17, 11, 330, 6763, 7258, 788, 220, 20, 3417, 715, 151658, 198, 27, 15918, 397, 4913, 1313, 3252, 1688, 2198, 1688, 22317, 606, 3252, 9986, 8929, 1889, 581, 900, 22785, 2198, 4684, 3252, 6025, 21080, 389, 3151, 4034, 553, 1667, 1008, 7375, 11, 15562, 304, 389, 264, 3151, 5537, 315, 458, 2168, 553, 98937, 432, 3118, 389, 264, 30618, 3745, 320, 58456, 8, 323, 458, 10101, 1633, 2383, 47891, 13786, 22317, 1313, 3252, 1700, 2198, 13193, 22317, 58456, 62, 17, 67, 22317, 1313, 3252, 1653, 2198, 3615, 22317, 1313, 3252, 4082, 58640, 1065, 4353, 788, 19, 1335, 2810, 4353, 788, 19, 1335, 4684, 3252, 785, 30618, 3745, 315, 279, 5537, 311, 15562, 304, 11, 438, 508, 87, 16, 11, 379, 16, 11, 856, 17, 11, 379, 17, 1125, 1380, 320, 87, 16, 11, 379, 16, 8, 374, 279, 1909, 7950, 9131, 323, 320, 87, 17, 11, 379, 17, 8, 374, 279, 5622, 6701, 9131, 1189, 51193, 1502, 22317, 1313, 3252, 917, 2198, 4684, 3252, 785, 829, 476, 2383, 315, 279, 1633, 304, 279, 5189, 30618, 3745, 320, 12807, 568, 30975, 1335, 6279, 36799, 58456, 1341, 3417, 532, 522, 15918, 1339, 2, 2585, 311, 1618, 264, 5392, 198, 5598, 264, 2951, 1633, 448, 729, 829, 323, 5977, 2878, 220, 151657, 151658, 11874, 9492, 510, 151657, 198, 4913, 606, 788, 366, 1688, 11494, 8066, 330, 16370, 788, 366, 2116, 56080, 40432, 31296, 151658, 271, 334, 13314, 95518, 715, 151657, 715, 4913, 606, 788, 330, 9986, 8929, 1889, 581, 900, 22785, 497, 330, 16370, 788, 5212, 58456, 62, 17, 67, 788, 508, 16, 15, 11, 220, 17, 15, 11, 220, 16, 15, 15, 11, 220, 17, 15, 15, 1125, 330, 1502, 788, 330, 1782, 23268, 389, 279, 18010, 30975, 715, 151658, 151645, 198, 151644, 872, 198, 151652, 151656, 151653, 198, 9485, 525, 279, 14087, 315, 264, 2766, 13, 8427, 279, 1850, 4226, 311, 279, 2701, 5248, 62626, 3405, 3118, 389, 279, 2766, 13, 39533, 448, 1172, 279, 6524, 320, 32, 11, 425, 11, 356, 11, 476, 422, 8, 315, 279, 4396, 2999, 624, 14582, 25, 2585, 1657, 2518, 38986, 525, 3403, 279, 39411, 518, 279, 835, 315, 419, 2766, 5267, 32, 13, 220, 16, 624, 33, 13, 220, 19, 624, 34, 13, 220, 17, 624, 35, 13, 220, 18, 624, 16141, 25, 220, 151645, 198, 151644, 77091, 198]])
imput_prompt_id = imput_prompt_id.to('cuda:0')

output = hf_model.generate(
    input_ids=imput_prompt_id,
    max_new_tokens=60000,
)

# tokenize decode
output = tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)
print(f"[DEBUG] [output] : \n =========> \n{output}")
